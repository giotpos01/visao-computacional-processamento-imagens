{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificadores e decodificadores\n",
    "\n",
    "Um codificador extrai atributos de uma imagem em diferentes resoluções. Um decodificador processa esses atributos para extrair uma imagem de mesmo tamanho que a imagem de entrada do codificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um decodificador\n",
    "\n",
    "Iremos criar um decodificar do tipo *Feature Pyramid Network*. Ele recebe uma lista de tensores contendo ativações de camadas de um codificador e combina essas ativações para gerar um único tensor de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 112, 112])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def conv_norm(in_channels, out_channels, kernel_size=3, act=True):\n",
    "    \"\"\"Cria uma camada conv->batchnorm com uma ativação relu opcional.\"\"\"\n",
    "\n",
    "    layer = [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                padding=kernel_size//2, bias=False),\n",
    "        nn.BatchNorm2d(out_channels)\n",
    "    ]\n",
    "    if act:\n",
    "        layer += [nn.ReLU()]\n",
    "    \n",
    "    return nn.Sequential(*layer)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Recebe a ativação do nível anterior do decoder `x_dec` e a ativação do \n",
    "    encoder `x_enc`. É assumido que `x_dec` possui uma resolução espacial\n",
    "    menor que `x_enc` e que `x_enc` possui número de canais diferente\n",
    "    de `x_dec`.\n",
    "    \n",
    "    O módulo ajusta a resolução de `x_dec` para ser igual a `x_enc` e o número\n",
    "    de canais de `x_enc` para ser igual a `x_dec`.\"\"\"\n",
    "\n",
    "    def __init__(self, enc_channels, dec_channels):\n",
    "        super().__init__()\n",
    "        self.channel_adjust = conv_norm(enc_channels, dec_channels, kernel_size=1,\n",
    "                                        act=False)\n",
    "        self.mix = conv_norm(dec_channels, dec_channels)\n",
    "\n",
    "    def forward(self, x_enc, x_dec):\n",
    "        x_dec_int = F.interpolate(x_dec, size=x_enc.shape[-2:], mode=\"nearest\")\n",
    "        x_enc_ad = self.channel_adjust(x_enc)\n",
    "        y = x_dec_int + x_enc_ad\n",
    "        return self.mix(y)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Na criação da instância, recebe uma lista com o número de canais das\n",
    "    ativações do codificador. Essa lista é necessária para criação das\n",
    "    camadas de convolução. O método .forward irá receber uma lista de tensores\n",
    "    e gerar uma saída com a resolução do primeiro tensor e número de canais\n",
    "    dado por `decoder_channels`. \n",
    "    \n",
    "    Por exemplo, suponha que as ativações extraídas de um codificador possuem \n",
    "    as dimensões:\n",
    "    \n",
    "    [(64,112,112), (128,56,56), (256,28,28), (512,14,14)]\n",
    "\n",
    "    Então devemos usar `encoder_channels_list=[64, 128, 256, 512]`, e o método\n",
    "    .forward irá gerar um tensor de tamanho (`decoder_channels`,112,112).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_channels_list, decoder_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # Inverte lista para facilitar interpretação\n",
    "        encoder_channels_list = encoder_channels_list[::-1]\n",
    "\n",
    "        self.middle = conv_norm(encoder_channels_list[0], decoder_channels)\n",
    "        blocks = []\n",
    "        for channels in encoder_channels_list[1:]:\n",
    "            blocks.append(DecoderBlock(channels, decoder_channels))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        # Inverte lista para facilitar interpretação\n",
    "        features = features[::-1]\n",
    "\n",
    "        x = self.middle(features[0])\n",
    "        for idx in range(1, len(features)):\n",
    "            # Temos um bloco a menos do que nro de features, por isso\n",
    "            # o idx-1\n",
    "            x = self.blocks[idx-1](features[idx], x)\n",
    "\n",
    "        return x\n",
    "\n",
    "encoder_channels_list = [64, 128, 256]\n",
    "decoder_channels = 64\n",
    "\n",
    "decoder = Decoder(encoder_channels_list, decoder_channels)\n",
    "# Lista de atributos de teste, representando os atributos extraídos de um\n",
    "# codificador\n",
    "x = [\n",
    "    torch.rand(1, 64, 112, 112), \n",
    "    torch.rand(1, 128, 56, 56), \n",
    "    torch.rand(1, 256, 28, 28)\n",
    "]\n",
    "res = decoder(x)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decodificação de atributos de uma ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"Amostra ativações de um modelo ResNet do Pytorch e cria um decodificador.\"\"\"\n",
    "\n",
    "    def __init__(self, resnet_encoder, decoder_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Codificador\n",
    "        self.resnet_encoder = resnet_encoder\n",
    "        # Extrai lista de canais dos atributos do codificador para criação de\n",
    "        # decodificador\n",
    "        encoder_channels_list = self.get_channels()\n",
    "        # Decodificador\n",
    "        self.decoder = Decoder(encoder_channels_list, decoder_channels)\n",
    "        # Camada final de classificação\n",
    "        self.classification = nn.Conv2d(decoder_channels, num_classes, 3, padding=1)\n",
    "        \n",
    "    def get_features(self, x):\n",
    "        \"\"\"Extrai as ativações intermediárias de uma resnet.\"\"\"\n",
    "        \n",
    "        features = []\n",
    "        re = self.resnet_encoder\n",
    "        x = re.conv1(x)\n",
    "        x = re.bn1(x)\n",
    "        x = re.relu(x)\n",
    "        features.append(x)\n",
    "        x = re.maxpool(x)\n",
    "\n",
    "        x = re.layer1(x)\n",
    "        features.append(x)\n",
    "        x = re.layer2(x)\n",
    "        features.append(x)\n",
    "        x = re.layer3(x)\n",
    "        features.append(x)\n",
    "        x = re.layer4(x)\n",
    "        features.append(x)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def get_channels(self):\n",
    "        \"\"\"Obtém o número de canais de cada tensor de features extraído pelo\n",
    "        encoder.\"\"\"\n",
    "\n",
    "        re = self.resnet_encoder\n",
    "        # Armazena se o modelo estava em modo treinamento\n",
    "        training = re.training\n",
    "        re.eval()\n",
    "\n",
    "        x = torch.zeros(1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            features = self.get_features(x)\n",
    "        encoder_channels_list = [f.shape[1] for f in features]\n",
    "\n",
    "        # Volta para treinamento\n",
    "        if training:\n",
    "            re.train()\n",
    "\n",
    "        return encoder_channels_list\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_shape = x.shape[-2:]\n",
    "        features = self.get_features(x)\n",
    "        x = self.decoder(features)\n",
    "\n",
    "        # Interpola o resultado para ter a mesma dimensão que a imagem de entrada\n",
    "        if x.shape[-2:]!=in_shape:\n",
    "            x = F.interpolate(x, size=in_shape, mode=\"nearest\")\n",
    "\n",
    "        x = self.classification(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "encoder = models.resnet18()\n",
    "model = EncoderDecoder(encoder, 64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 224, 224])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 224, 224)\n",
    "y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Medindo a qualidade da segmentação\n",
    "\n",
    "Precisamos de métricas de performance para quantificar a qualidade da segmentação produzida por um modelo. Para isso, precisamos primeiro transformar os resultados do modelo em uma segmentação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicação da função softmax ao longo da dimensão dos canais, o que gera probabilidades para \n",
    "# cada classe e para cada pixel da imagem\n",
    "probs = y.softmax(dim=1)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A função argmax retorna, para cada pixel, o índice do canal com a maior probabilidade,\n",
    "# ou seja, a classe mais provável para aquele pixel\n",
    "preds = probs.argmax(dim=1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para problemas de classificação binária (duas classes), é possível que a saída da rede seja um único canal ou dois canais. A função `scores_to_segmentation` abaixo gera a segmentação considerando esses dois casos possíveis. A função também possibilita que seja definido um limiar de probabilidades. Apenas píxeis com probabilidade acima do limiar serão considerados como positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 224, 224])\n",
      "torch.Size([16, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "def scores_to_segmentation(scores, threshold=0.5):\n",
    "    \"\"\"Gera uma máscara binária a partir de scores de um modelo de segmentação.\n",
    "    A função assume que scores é um tensor 4D com a forma (batch_size, num_channels, height, width).\n",
    "    O parâmetro threshold é usado para limiarizar as probabilidades da classe positiva.\"\"\"\n",
    "\n",
    "    num_channels = scores.shape[1]\n",
    "    if num_channels==1:\n",
    "        # Calcula as probabilidades. O tensor possui apenas um canal, que, por padrão, está \n",
    "        # relacionado com as probabilidades da classe positiva.\n",
    "        probs = scores.sigmoid()[:, 0]\n",
    "    elif num_channels==2:\n",
    "        # Calcula probabilidades para a classe 1\n",
    "        probs = scores.softmax(dim=1)[:, 1]\n",
    "    \n",
    "    preds = probs > threshold  \n",
    "\n",
    "    return preds\n",
    "\n",
    "y_one = torch.rand(16, 1, 224, 224)\n",
    "y_two = torch.rand(16, 2, 224, 224)\n",
    "\n",
    "print(scores_to_segmentation(y_one).shape)\n",
    "print(scores_to_segmentation(y_two).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então fazer uma função que calcula algumas métricas relevantes de qualidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5006),\n",
       " tensor(0.5005),\n",
       " tensor(0.6285),\n",
       " tensor(0.3862),\n",
       " tensor(0.5572))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metrics(scores, targets, ignore_val=2):\n",
    "    \"\"\"Função que calcula a acurácia, precisão, revocação, Intersecção sobre a União (IoU) e \n",
    "    o score Dice.\"\"\"\n",
    "\n",
    "    preds = scores_to_segmentation(scores)\n",
    "\n",
    "    # Aplica um reshape nos tensores para transformá-los em 1D\n",
    "    pred = preds.reshape(-1)\n",
    "    targets = targets.reshape(-1)\n",
    "\n",
    "    # Mantém apenas valores para os quais target!=2. O valor 2 indica píxeis\n",
    "    # a serem ignorados\n",
    "    pred = pred[targets!=ignore_val]\n",
    "    targets = targets[targets!=ignore_val]\n",
    "\n",
    "    # Verdadeiro positivos\n",
    "    tp = ((targets==1) & (pred==1)).sum()\n",
    "    # Verdadeiro negativos\n",
    "    tn = ((targets==0) & (pred==0)).sum()\n",
    "    # Falso positivos\n",
    "    fp = ((targets==0) & (pred==1)).sum()\n",
    "    # Falso negativos\n",
    "    fn = ((targets==1) & (pred==0)).sum()\n",
    "\n",
    "    # Algumas métricas interessantes para medir a qualidade do resultado\n",
    "    # Acurácia: Fração de píxeis corretos\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    # Precisão: Fração de píxeis classificados como positivos que são realmente positivos\n",
    "    prec = tp/(tp+fp)\n",
    "    # Revocação: Fração de píxeis positivos que foram corretamente classificados como positivos\n",
    "    rev = tp/(tp+fn)\n",
    "    # Intersecção sobre a união (IoU)\n",
    "    iou = tp/(tp+fp+fn)\n",
    "    # Score Dice\n",
    "    dice = 2*tp/(2*tp+fp+fn)\n",
    "\n",
    "    return acc, prec, rev, iou, dice\n",
    "\n",
    "# Batch de imagens artificial\n",
    "imgs = torch.rand(8, 3, 224, 224)\n",
    "# Targets artificiais, com valores 0, 1 e 2\n",
    "targets = torch.randint(0, 3, (8, 224, 224))\n",
    "scores = model(imgs)\n",
    "metrics(scores, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
