{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance em GPU [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chcomin/curso-visao-computacional-2025/blob/main/M13_desempenho_e_eficiencia/2%20-%20Abordagens%20para%20melhorar%20a%20performance%20(GPU).ipynb)\n",
    "\n",
    "Veremos algumas estratégias para melhorar a perfomance em GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão numérica\n",
    "\n",
    "GPUs modernas realizam operações de forma muito mais eficiente em float16. Mas operações em float16 possuem menor precisão, então é preciso tomar cuidado com a estabilidade numérica dos resultados. Existem algumas abordagens para realizar operações em menor precisão e ao mesmo tempo evitar erros numéricos. \n",
    "\n",
    "Compararemos as seguintes situações que possuem diferentes relações custo x precisão:\n",
    "\n",
    "1. Operações em float64, o que dá o resultado mais preciso possível, mas é menos eficiente\n",
    "2. Operações em float32, que é o padrão do Pytorch\n",
    "3. O Pytorch disponibiliza a chamada *automatic mixed precision*. Quando é detectado que uma operação pode ser realizada sem muita perda de precisão, o Pytorch automaticamente realiza a operação em menor precisão. Para isso, é usado o contexto `torch.autocast`\n",
    "4. Realizar operações em float16, o que é extremamente eficiente em GPUs modernas. Mas é preciso tomar cuidado, por exemplo, não é recomendado realizar o backpropagation em float16\n",
    "5. Em GPUs recentes o Pytorch possui a função `torch.set_float32_matmul_precision`, que permite o uso de um tipo especial de dado, o chamado *tensorfloat32*. Esse tipo de dado é usado exclusivamente por tensor cores. Ele permite uma precisão próxima de float32 mas com a eficiência de float16\n",
    "\n",
    "Aplicaremos essas técnicas em multiplicações matriciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class PerfRecorder:\n",
    "    \"\"\"Registra o tempo de execução na GPU e o uso de memória.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.gpu_start = torch.cuda.Event(enable_timing=True)\n",
    "        self.gpu_end = torch.cuda.Event(enable_timing=True)  \n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Inicia registro.\"\"\"\n",
    "\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        self.gpu_start.record() \n",
    "\n",
    "    def end(self):\n",
    "        \"\"\"Encerra registro.\"\"\"\n",
    "\n",
    "        self.gpu_end.record()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Tempo de execução na GPU, em ms\n",
    "        t_gpu = self.gpu_start.elapsed_time(self.gpu_end)\n",
    "        # Uso de memória em GiB\n",
    "        max_memory = torch.cuda.max_memory_allocated()/2**30\n",
    "    \n",
    "        return t_gpu, max_memory\n",
    "    \n",
    "def benchmark(shape, dtype, n=5, n_warm=2):\n",
    "    \"\"\"Realiza `n` multiplicações matriciais entre matrizes de tamanho\n",
    "    shape[0]xshape[1] x shape[1]xshape[0]. Retorna o tempo médio de cada \n",
    "    multiplicação, a memória utilizada e a média dos valores do resultado.\"\"\"\n",
    "\n",
    "    recorder = PerfRecorder()\n",
    "\n",
    "    nr, nc = shape\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    x1 = torch.randn(nr, nc, dtype=dtype, device=\"cuda\")\n",
    "    x2 = torch.randn(nc, nr, dtype=dtype, device=\"cuda\")\n",
    "\n",
    "    for _ in range(n_warm):\n",
    "        _ = torch.matmul(x1, x2)\n",
    "\n",
    "    recorder.start()\n",
    "    for _ in range(n):\n",
    "        r = torch.matmul(x1, x2)\n",
    "    t_gpu, max_memory = recorder.end()\n",
    "    t_gpu /= n\n",
    "\n",
    "    # Média dos valores do resultado do cálculo\n",
    "    mean_val = r.abs().mean().item()\n",
    "    \n",
    "    return t_gpu, max_memory, mean_val\n",
    "\n",
    "# Memória disponível na GPU em GiB\n",
    "mem_size = 12\n",
    "# Quantidade de valores que podem ser alocados em float64, excluindo 2 GiB para\n",
    "# evitar problemas de memória\n",
    "nv = (mem_size-2)*2**30//8\n",
    "# //2 porque vamos alocar duas matrizes\n",
    "nv = nv//2\n",
    "# Tamanho das matrizes. As dimensões terem ao menos tamanho 512 garante que\n",
    "# a GPU será utilizada ao máximo\n",
    "mat_shape = (512, nv//512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempos (ms):\n",
      "float64: 1260.8\n",
      "float32: 42.8\n",
      "float16: 11.1\n",
      "\n",
      "Memória (GiB):\n",
      "float64: 10.0\n",
      "float32: 5.0\n",
      "float16: 2.5\n",
      "\n",
      "Média dos valores:\n",
      "float64: 914.979\n",
      "float32: 914.738\n",
      "float16: 912.500\n"
     ]
    }
   ],
   "source": [
    "# float64\n",
    "t_f64, m_f64, v_f64 = benchmark(mat_shape, torch.float64)\n",
    "# float32\n",
    "t_f32, m_f32, v_f32 = benchmark(mat_shape, torch.float32)\n",
    "# float16\n",
    "t_f16, m_f16, v_f16 = benchmark(mat_shape, torch.float16)\n",
    "\n",
    "print(\"Tempos (ms):\")\n",
    "print(f\"float64: {t_f64:.1f}\\nfloat32: {t_f32:.1f}\\nfloat16: {t_f16:.1f}\")\n",
    "\n",
    "print(\"\\nMemória (GiB):\")\n",
    "print(f\"float64: {m_f64:.1f}\\nfloat32: {m_f32:.1f}\\nfloat16: {m_f16:.1f}\")\n",
    "\n",
    "print(\"\\nMédia dos valores:\")\n",
    "print(f\"float64: {v_f64:.3f}\\nfloat32: {v_f32:.3f}\\nfloat16: {v_f16:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note as diferenças de tempo. Os cálculos demoram muito mais em float64, e a multiplicação em float16 é mais de 3x mais rápida do que em float32! Isso representa um potencial de speedup de mais de 3x somente modificando a precisão! Mas note que os resultados apresentam pequenas diferenças.\n",
    "\n",
    "O Pytorch possui duas abordagens para realizar cálculos em meia precisão :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempos (ms):\n",
      "autocast: 21.2\n",
      "tensorfloat32: 22.2\n",
      "\n",
      "Memória (GiB):\n",
      "autocast: 7.5\n",
      "tensorfloat32: 5.0\n",
      "\n",
      "Resultados:\n",
      "autocast: 914.500\n",
      "tensorfloat32: 914.558\n"
     ]
    }
   ],
   "source": [
    "# Autocast para float16, em operações selecionadas. Multiplicação matricial\n",
    "# é uma dessas operações\n",
    "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "    t_af16, m_af16, v_af16 = benchmark(mat_shape, torch.float32)\n",
    "\n",
    "# Uso do formato tf32 (tensorfloat32) para realizar a multiplicação\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "t_tf32, m_tf32, v_tf32 = benchmark(mat_shape, torch.float32)\n",
    "\n",
    "print(\"Tempos (ms):\")\n",
    "print(f\"autocast: {t_af16:.1f}\\ntensorfloat32: {t_tf32:.1f}\")\n",
    "\n",
    "print(\"\\nMemória (GiB):\")\n",
    "print(f\"autocast: {m_af16:.1f}\\ntensorfloat32: {m_tf32:.1f}\")\n",
    "\n",
    "print(\"\\nResultados:\")\n",
    "print(f\"autocast: {v_af16:.3f}\\ntensorfloat32: {v_tf32:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O autocast e o formato tf32 permitem um speedup em relação à float32. \n",
    "\n",
    "Há também o formato bfloat32 que possui a mesma magnitude que float32 mas menos resolução. As informações sobre os formatos do Pytorch são:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info.max=3.4028234663852886e+38, info.smallest_normal=1.1754943508222875e-38, info.eps=1.1920928955078125e-07\n",
      "info.max=65504.0, info.smallest_normal=6.103515625e-05, info.eps=0.0009765625\n",
      "info.max=3.3895313892515355e+38, info.smallest_normal=1.1754943508222875e-38, info.eps=0.0078125\n"
     ]
    }
   ],
   "source": [
    "def pformat(format):\n",
    "    info = torch.finfo(format)\n",
    "    print(f\"{info.max=}, {info.smallest_normal=}, {info.eps=}\")\n",
    "\n",
    "pformat(torch.float32)\n",
    "pformat(torch.float16)\n",
    "pformat(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteca bitsandbytes\n",
    "\n",
    "A biblioteca bitsandbytes possibilita quantizar os parâmetros de camadas lineares, o que reduz o custo de memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 torch.float32\n",
      "512 torch.uint8\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from bitsandbytes.nn import Linear4bit\n",
    "\n",
    "n = 32\n",
    "# Modelo em float32\n",
    "model = nn.Linear(n, n)\n",
    "\n",
    "# Criação de uma camada Linear4bit e cópia dos pesos do modelo\n",
    "quantized_model = Linear4bit(n, n)\n",
    "quantized_model.load_state_dict(model.state_dict())\n",
    "# O modelo é quantizado ao copiar para a GPU:\n",
    "quantized_model = quantized_model.to(\"cuda\") \n",
    "\n",
    "print(model.weight.numel(), model.weight.dtype)\n",
    "print(quantized_model.weight.numel(), quantized_model.weight.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo original com 1024 parâmetros passou a ocupar 512\\*8 bits. Isso corresponde a 512\\*8/1024 = 4 bits/parâmetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiros 10 valores do modelo quantizado:\n",
      "tensor([[125],\n",
      "        [115],\n",
      "        [239],\n",
      "        [169],\n",
      "        [179],\n",
      "        [ 89],\n",
      "        [ 58],\n",
      "        [218],\n",
      "        [217],\n",
      "        [196]], device='cuda:0', dtype=torch.uint8)\n",
      "Informação utilizada para recuperar os pesos quando a camada receber uma entrada:\n",
      "{'quant_type': 'fp4', 'absmax': tensor([206, 181,  51, 204,  94, 194,  54, 200, 212, 204,  23, 213,   0, 195,\n",
      "         30, 213], device='cuda:0', dtype=torch.uint8), 'blocksize': 64, 'quant_map': tensor([ 0.0000,  0.0052,  0.6667,  1.0000,  0.3333,  0.5000,  0.1667,  0.2500,\n",
      "         0.0000, -0.0052, -0.6667, -1.0000, -0.3333, -0.5000, -0.1667, -0.2500],\n",
      "       device='cuda:0'), 'dtype': 'float32', 'shape': (32, 32), 'nested_absmax': tensor([0.0055], device='cuda:0'), 'nested_blocksize': 256, 'nested_quant_map': tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
      "        -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
      "        -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
      "        -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
      "        -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
      "        -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
      "        -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
      "        -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
      "        -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
      "        -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
      "        -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
      "        -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
      "        -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
      "        -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
      "        -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
      "        -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
      "        -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
      "        -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
      "        -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
      "        -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
      "        -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
      "        -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
      "        -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
      "        -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
      "        -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
      "        -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
      "         7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
      "         1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
      "         7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
      "         2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
      "         5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
      "         8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
      "         1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
      "         2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
      "         4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
      "         5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
      "         7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
      "         8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
      "         9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
      "         1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
      "         2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
      "         3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
      "         3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
      "         4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
      "         5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
      "         5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
      "         6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
      "         7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
      "         7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
      "         8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
      "         9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
      "         1.0000e+00], device='cuda:0'), 'nested_dtype': 'float32', 'nested_offset': 0.17440412938594818}\n"
     ]
    }
   ],
   "source": [
    "print(\"Primeiros 10 valores do modelo quantizado:\")\n",
    "print(quantized_model.weight[:10])\n",
    "\n",
    "print(\"Informação utilizada para recuperar os pesos quando a camada receber uma entrada:\")\n",
    "print(quantized_model.quant_state.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memória *page-locked*\n",
    "\n",
    "Dados copiados da CPU para a GPU não podem residir em memória pageada, pois a cópia de dados é feita utilizando DMA (Direct Memory Access). Por padrão, um tensor do Pytorch é alocado em memória pageada. É possível criar um tensor em um intervalo de memória não pageada pelo sistema. Esse processo é denominado de \"pinned memory\", ou page-locked. Ele aumenta de forma significativa o desempenho da cópia dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempos (ms):\n",
      "pin=False: 213.9\n",
      "pin=True: 108.8\n"
     ]
    }
   ],
   "source": [
    "def copy(mat_shape, pin):\n",
    "\n",
    "    recorder = PerfRecorder()\n",
    "\n",
    "    x = torch.rand(mat_shape)\n",
    "    if pin:\n",
    "        x = x.pin_memory()\n",
    "\n",
    "    recorder.start()\n",
    "    x = x.to(\"cuda\")\n",
    "    t_gpu, _ = recorder.end()\n",
    "    \n",
    "    return t_gpu\n",
    "\n",
    "t_nopin = copy(mat_shape, False)\n",
    "t_pin = copy(mat_shape, True)\n",
    "\n",
    "print(\"Tempos (ms):\")\n",
    "print(f\"pin=False: {t_nopin:.1f}\\npin=True: {t_pin:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiar tensores com pin_memory habilitado é quase 2x mais rápido. Isso é muito relevante, considerando que copiar dados da CPU para a GPU é uma operação extremamente custosa (note que demora mais para copiar uma matriz do que para realizar a multiplicação matricial entre centenas de milhões de valores).\n",
    "\n",
    "Os dataloaders do Pytorch possuem uma parâmetro `pin_memory` que quando True utiliza essa técnica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint de gradiente/ativação\n",
    "\n",
    "Checkpoint de gradiente é uma técnica que permite utilizar menos memória da GPU em troca de um custo computacional um pouco maior. Uma ou mais camadas do modelo são definidas como *checkpoints*. No processamento direto (forward), a ativação de uma camada checkpoint é salva, e as ativações das camadas seguintes não são salvas no grafo de computação. No momento do cálculo de gradientes, as ativações a partir da camada checkpoint são recalculadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo base:\n",
      "Tempo (ms): 955.8\n",
      "Memória (GiB): 8.2\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "\n",
    "def bench_model(model, bs, n=5, n_warm=2):\n",
    "    \"\"\"Mede o tempo de execução e uso de memória de um loop de treinamento.\"\"\"\n",
    "\n",
    "    optim = torch.optim.SGD(model.parameters())\n",
    "    x = torch.rand(bs, 3, 224, 224, device=\"cuda\")\n",
    "    recorder = PerfRecorder()\n",
    "\n",
    "    for _ in range(n_warm):\n",
    "        _ = model(x)\n",
    "\n",
    "    recorder.start()\n",
    "    for _ in range(n):\n",
    "        scores = model(x)\n",
    "        loss = scores.mean()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    t_gpu, max_memory = recorder.end()\n",
    "\n",
    "    return t_gpu, max_memory\n",
    "\n",
    "model = resnet50().to(\"cuda\")\n",
    "\n",
    "t_resnet, m_resnet = bench_model(model, bs=96)\n",
    "print(\"Modelo base:\")\n",
    "print(f\"Tempo (ms): {t_resnet:.1f}\\nMemória (GiB): {m_resnet:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo com checkpoint\n",
      "Tempo (ms): 1124.6\n",
      "Memória (GiB): 3.6\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "\n",
    "class ResNetChkp(nn.Module):\n",
    "    \"\"\"Cria um modelo ResNet utilizando a técnica de checkpoint de gradiente.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "\n",
    "        # Grupos de camadas da ResNet. Os primeiros dois grupos possuem \n",
    "        # ativações de alta resolução\n",
    "        self.group1 = nn.Sequential(\n",
    "            model.conv1,\n",
    "            model.bn1,\n",
    "            model.relu,\n",
    "            model.maxpool,\n",
    "            model.layer1[:2]\n",
    "        )\n",
    "        self.group2 = nn.Sequential(\n",
    "            model.layer1[2:],\n",
    "            model.layer2[:2]\n",
    "        )\n",
    "        self.group3 = nn.Sequential(\n",
    "            model.layer2[2:],\n",
    "            model.layer3,\n",
    "            model.layer4,\n",
    "            model.avgpool    \n",
    "        )\n",
    "        self.fc = model.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Aplica grupos 1 e 2 utilizando checkpoint. As ativações das camadas não\n",
    "        # serão salvas no grafo de computação. Quando elas forem necessárias,\n",
    "        # serão recalculadas através de uma nova aplicação das camadas na entrada\n",
    "        x = checkpoint(self.group1, x, use_reentrant=False)\n",
    "        x = checkpoint(self.group2, x, use_reentrant=False)\n",
    "        x = self.group3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "resnet_ckp = ResNetChkp(model)\n",
    "\n",
    "t_resnet, m_resnet = bench_model(resnet_ckp, bs=96)\n",
    "print(\"Modelo com checkpoint\")\n",
    "print(f\"Tempo (ms): {t_resnet:.1f}\\nMemória (GiB): {m_resnet:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo com checkpoint utiliza 43% da memória do modelo original e possui tempo de processamento 15% maior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA\n",
    "\n",
    "A técnica LoRA consiste em realizar o refinamento de um modelo através de matrizes que aproximam a alteração que os parâmetros do modelo sofrem durante o refinamento. Para entender a motivação da técnica, veremos primeiro como uma matriz pode ser aproximada através da técnica SVD (Singular Value Decomposition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def print_tensor(message, tensor):\n",
    "    \"\"\"Função auxiliar para imprimir apenas a parte inicial de um tensor.\"\"\"\n",
    "\n",
    "    torch.set_printoptions(sci_mode=False)\n",
    "    print(f\"{message}:\\n{tensor[:4, :8]}\")\n",
    "\n",
    "weights = torch.load(\"../data/fake_weights.pt\")\n",
    "weights_tuned = torch.load(\"../data/fake_weights_tuned.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponha que os parâmetros de uma camada do modelo estão contidos na matrix `weights`. Após o refinamento desse modelo, os parâmetros dessa camada passarão a ser `weights_tuned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos originais:\n",
      "tensor([[-1.4515, -0.8654,  2.6835, -0.3196, -1.0925,  1.6211, -0.1472,  0.3080],\n",
      "        [ 1.1415, -1.2126,  1.3641, -0.2505,  0.3801,  0.3263, -1.2921,  1.2469],\n",
      "        [-0.7303,  0.4232,  1.3552,  0.6914, -1.7132,  1.2654, -1.2716, -0.3117],\n",
      "        [-1.7357,  0.9811,  0.7828, -0.0453,  0.4603,  0.5089,  0.3502,  1.7055]])\n",
      "\n",
      "Pesos refinados:\n",
      "tensor([[30.8778,  6.8560, 13.7701, 20.8789, 53.6016, 28.6116, 39.8990, 55.8736],\n",
      "        [39.7091,  6.4848, 14.9711, 24.6620, 70.5781, 30.5044, 45.9103, 72.3525],\n",
      "        [35.3618,  3.9190, 14.7634, 22.2599, 75.6303, 23.2517, 41.1261, 77.0293],\n",
      "        [43.5545,  7.3873, 17.0924, 27.6478, 90.6992, 31.4841, 54.5752, 92.5970]])\n",
      "\n",
      "Alteração sofrida pelos pesos durante o refinamento::\n",
      "tensor([[32.3293,  7.7214, 11.0866, 21.1985, 54.6941, 26.9905, 40.0462, 55.5656],\n",
      "        [38.5676,  7.6974, 13.6070, 24.9125, 70.1980, 30.1781, 47.2024, 71.1056],\n",
      "        [36.0922,  3.4957, 13.4082, 21.5684, 77.3435, 21.9862, 42.3977, 77.3410],\n",
      "        [45.2902,  6.4062, 16.3096, 27.6931, 90.2389, 30.9752, 54.2249, 90.8915]])\n"
     ]
    }
   ],
   "source": [
    "print_tensor(\"Pesos originais\", weights)\n",
    "print_tensor(\"\\nPesos refinados\", weights_tuned)\n",
    "\n",
    "delta_weights = weights_tuned - weights\n",
    "print_tensor(\"\\nAlteração sofrida pelos pesos durante o refinamento:\", delta_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica SVD permite decompor uma matriz em uma base de vetores que aproximam a matriz original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparação dos pesos')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "U, S, V = torch.linalg.svd(delta_weights)\n",
    "\n",
    "# Aproximação da matriz de pesos utilizando um subespaço de dimensão `rank`\n",
    "rank = 2\n",
    "A = S[:rank]*U[:, :rank]\n",
    "B = V[:rank]\n",
    "\n",
    "delta_weights_approx = A @ B\n",
    "\n",
    "plt.scatter(delta_weights.flatten(), delta_weights_approx.flatten(), s=1)\n",
    "plt.xlabel(\"Pesos originais\")\n",
    "plt.ylabel(\"Pesos aproximados\")\n",
    "plt.title(\"Comparação dos pesos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 500]) torch.Size([500, 2]) torch.Size([2, 500])\n"
     ]
    }
   ],
   "source": [
    "print(weights_tuned.shape, A.shape, B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, os pesos refinados podem ser escritos como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos refinados::\n",
      "tensor([[30.8778,  6.8560, 13.7701, 20.8789, 53.6016, 28.6116, 39.8990, 55.8736],\n",
      "        [39.7091,  6.4848, 14.9711, 24.6620, 70.5781, 30.5044, 45.9103, 72.3525],\n",
      "        [35.3618,  3.9190, 14.7634, 22.2599, 75.6303, 23.2517, 41.1261, 77.0293],\n",
      "        [43.5545,  7.3873, 17.0924, 27.6478, 90.6992, 31.4841, 54.5752, 92.5970]])\n",
      "\n",
      "Aproximação dos pesos refinados::\n",
      "tensor([[30.7542,  6.8657, 13.6904, 20.7707, 53.6183, 28.6010, 39.8825, 55.8973],\n",
      "        [39.8579,  6.5943, 14.9058, 24.4664, 70.7019, 30.3698, 46.1782, 72.3616],\n",
      "        [35.4189,  3.8739, 14.7981, 22.1249, 75.6902, 23.1462, 41.3680, 77.1529],\n",
      "        [43.5485,  7.5121, 17.1630, 27.7505, 90.6667, 31.4690, 54.7331, 92.3792]])\n"
     ]
    }
   ],
   "source": [
    "weights_tunned_approx = weights + A@B\n",
    "\n",
    "print_tensor(\"Pesos refinados:\", weights_tuned)\n",
    "print_tensor(\"\\nAproximação dos pesos refinados:\", weights_tunned_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao invés de refinar a matriz `weights` possuindo $500*500 = 250000$ valores, podemos refinar as matrizes `A` e `B` possuindo $1000$ elementos cada. Em geral, ao invés de refinar uma matriz possuindo $n*m$ parâmetros, podemos refinar duas matrizes com um total de $n*r + m*r$ parâmetros. Se $m=n$, temos uma redução de $n/2r$ no número de parâmetros.\n",
    "\n",
    "Por exemplo, as matrizes das camadas de atenção do modelo Llama 3 70B possuem tamanho $8192\\times 8192$. Um valor comum para o rank é 8. Com isso, ao invés de otimizar 67108864 parâmetros, a técnica LoRA permite otimizar apenas $2*8192*8=131072$ parâmetros. Uma redução de $\\times 500$ no número de parâmetros. Isso também reduz drasticamente o uso de memória.\n",
    "\n",
    "Uma outra vantagem do LoRA é que ela permite que modelos refinados em diferentes tarefas sejam rapidamente aplicados. O modelo base é mantido na memória, e apenas os parâmetros extra específicos de uma tarefa são trocados. Isso também permite compartilhar com a comunidade os parâmetros refinados com menor custo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acúmulo de gradientes\n",
    "\n",
    "O acúmulo de gradientes consiste em *simular* um valor de batch size utilizando batches menores. Ele é útil quando queremos reproduzir o mesmo batch size utilizado em um artigo mas a GPU não possui memória suficiente para tal.\n",
    "\n",
    "Suponha que a VRAM disponível suporta no máximo um batch size de 8 imagens. No exemplo abaixo, o treinamento terá um batch size efetivo de tamanho 32:\n",
    "\n",
    "```python\n",
    "gradient_accumulation_steps = 4\n",
    "for step, (imgs, targets) in enumerate(dl_train):\n",
    "    scores = model(imgs)\n",
    "    loss(scores, targets)\n",
    "    loss.backward()\n",
    "\n",
    "    if (step+1)%gradient_accumulation_steps == 0:\n",
    "        # Dá um passo após `gradient_accumulation_steps` batches\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilação do grafo de execução\n",
    "\n",
    "Cada operação realizada pelo Pytorch na GPU envolve a chamada de uma função cuda. Isso representa um custo adicional de comunicação entre CPU e GPU. Adicionalmente, existem diversas operações que podem ser otimizadas. Por exemplo, uma operação de convolução seguida de uma operação batchnorm pode ser representada por uma única operação linear dado que ambas as operações são lineares. Um loop de treinamento envolve chamar exatamente as mesma funções diversas vezes. O Pytorch permite compilar um grafo de executação que otimizará uma sequência de operações realizadas na GPU. Isso é feito através da função `torch.compile()`. Por exemplo, dado um modelo, podemos fazer:\n",
    "\n",
    "`model = torch.compile(model, fullgraph=True, dynamic=False)`\n",
    "\n",
    "O modelo pode então ser utilizado no loop de treinamento. Isso pode levar a speedups significativos. Mas há restrições nos tipos de modelos que podem ser compilados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
